{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Model developed in a Python 3.10.4 environment with the following packages required:\n",
    "\n",
    "- spacy\n",
    "- spacy-model-en_core_web_lg\n",
    "sklearn\n",
    "- pandas\n",
    "- openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "ASPECTS_ELEMENTS_MATERIALS_DF = pd.read_excel('./data/FCBS_Aspects-Elements-Materials_MachineReadable.xlsx')\n",
    "BUILDUPS_DETAILS_DF = pd.read_excel('./data/FCBS_Build Ups-Details_MachineReadable.xlsx')\n",
    "SECTORS_DF = pd.read_excel('./data/FCBS_Sectors-Subsectors_MachineReadable.xlsx')\n",
    "ICE_DB_DF = pd.read_csv('./data/ICE DB_Cleaned.csv')\n",
    "CLF_EMBODIED_CARBON_DF = pd.read_csv('./data/CLF Embodied Carbon_Cleaned.csv')\n",
    "RIBA_TARGETS_DF = pd.read_excel('./data/RIBA 2030-Targets_MachineReadable.xlsx')\n",
    "\n",
    "# Fill missing values\n",
    "def fill_missing_values(df):\n",
    "    return df.fillna(0)\n",
    "\n",
    "ASPECTS_ELEMENTS_MATERIALS_DF = fill_missing_values(ASPECTS_ELEMENTS_MATERIALS_DF)\n",
    "BUILDUPS_DETAILS_DF = fill_missing_values(BUILDUPS_DETAILS_DF)\n",
    "SECTORS_DF = fill_missing_values(SECTORS_DF)\n",
    "ICE_DB_DF = fill_missing_values(ICE_DB_DF)\n",
    "CLF_EMBODIED_CARBON_DF = fill_missing_values(CLF_EMBODIED_CARBON_DF)\n",
    "RIBA_TARGETS_DF = fill_missing_values(RIBA_TARGETS_DF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Text Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy to create patterns for identifying materials, building types, and element buildups\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Extract unique materials, building types, and element buildups\n",
    "unique_materials = ICE_DB_DF['Material'].unique()\n",
    "unique_sub_materials = ICE_DB_DF['Sub-material'].unique()\n",
    "all_materials = list(set(list(unique_materials) + list(unique_sub_materials)))\n",
    "all_materials = [str(material).strip().lower() for material in all_materials if pd.notna(material)]\n",
    "\n",
    "unique_building_types_clf = CLF_EMBODIED_CARBON_DF['Building Type'].unique()\n",
    "unique_building_uses_clf = CLF_EMBODIED_CARBON_DF['Building Use'].unique()\n",
    "unique_sectors = SECTORS_DF['Sector'].unique()\n",
    "unique_building_typologies = SECTORS_DF['Building Typology'].unique()\n",
    "unique_sub_sectors = SECTORS_DF['Sub-sector'].unique()\n",
    "all_building_types = list(set(list(unique_building_types_clf) + list(unique_building_uses_clf) +\n",
    "                              list(unique_sectors) + list(unique_building_typologies) + list(unique_sub_sectors)))\n",
    "all_building_types = [str(building_type).strip().lower() for building_type in all_building_types if pd.notna(building_type)]\n",
    "\n",
    "unique_building_aspects = ASPECTS_ELEMENTS_MATERIALS_DF['Building Aspect'].unique()\n",
    "unique_elements = ASPECTS_ELEMENTS_MATERIALS_DF['Element'].unique()\n",
    "unique_element_materials = ASPECTS_ELEMENTS_MATERIALS_DF['Material'].unique()\n",
    "all_element_buildups = list(set(list(unique_building_aspects) + list(unique_elements) + list(unique_element_materials)))\n",
    "all_element_buildups = [str(build_up).strip().lower() for build_up in all_element_buildups if pd.notna(build_up)]\n",
    "\n",
    "# Create a matcher for custom entities\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Function to create patterns from a list of terms\n",
    "def create_patterns(terms):\n",
    "    return [[{\"LOWER\": term}] for term in terms]\n",
    "\n",
    "# Create patterns for all materials, building types, and element buildups\n",
    "material_patterns = create_patterns(all_materials)\n",
    "building_type_patterns = create_patterns(all_building_types)\n",
    "element_buildup_patterns = create_patterns(all_element_buildups)\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add(\"MATERIAL\", material_patterns)\n",
    "matcher.add(\"BUILDING_TYPE\", building_type_patterns)\n",
    "matcher.add(\"ELEMENT_BUILDUP\", element_buildup_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse input description\n",
    "\n",
    "def parse_description(description):\n",
    "    doc = nlp(description)\n",
    "    size = 0\n",
    "    size_unit = 'square meters'\n",
    "    materials = []\n",
    "    building_types = []\n",
    "    element_buildups = []\n",
    "    location = 'unknown'\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        match_label = nlp.vocab.strings[match_id]\n",
    "        if match_label == 'MATERIAL':\n",
    "            materials.append(doc[start:end].text.lower())\n",
    "        elif match_label == 'BUILDING_TYPE':\n",
    "            building_types.append(doc[start:end].text.lower())\n",
    "        elif match_label == 'ELEMENT_BUILDUP':\n",
    "            element_buildups.append(doc[start:end].text.lower())\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'QUANTITY':\n",
    "            size = float(ent.text.replace(',', '').split()[0])\n",
    "            size_unit = ' '.join(ent.text.split()[1:])\n",
    "        elif ent.label_ == 'GPE':\n",
    "            location = ent.text.lower()\n",
    "        elif ent.label_ in ('ORG', 'FAC', 'PRODUCT'):\n",
    "            token_text = ent.text.lower()\n",
    "            if not building_types and any(nlp(token_text).similarity(nlp(b_type)) > 0.75 for b_type in all_building_types):\n",
    "                building_types.append(token_text)\n",
    "            if not materials and any(nlp(token_text).similarity(nlp(m)) > 0.75 for m in all_materials):\n",
    "                materials.append(token_text)\n",
    "    \n",
    "    if 'square feet' in size_unit or 'sq ft' in size_unit:\n",
    "        size *= 0.092903\n",
    "    \n",
    "    return {\n",
    "        'size': size,\n",
    "        'materials': materials,\n",
    "        'building_types': building_types,\n",
    "        'element_buildups': element_buildups,\n",
    "        'location': location\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "description = \"I am constructing a school building in New York that is 2000 square metres, primarily made of timber and steel. It will have pile foundations\"\n",
    "parsed_info = parse_description(description)\n",
    "print(parsed_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Assume you have a dataframe `df` with features and target variable `carbon_impact`\n",
    "# df = pd.DataFrame(parsed_features)\n",
    "# X = df.drop(columns=['carbon_impact'])\n",
    "# y = df['carbon_impact']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
