{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Model developed in a Python 3.11.9 environment with the following packages required:\n",
    "\n",
    "- spacy\n",
    "- spacy-model-en_core_web_sm\n",
    "- pandas\n",
    "- openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy.matcher import Matcher\n",
    "import spacy\n",
    "\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "ASPECTS_ELEMENTS_MATERIALS_DF = pd.read_excel('./data/FCBS_Aspects-Elements-Materials_MachineReadable.xlsx')\n",
    "BUILDUPS_DETAILS_DF = pd.read_excel('./data/FCBS_Build Ups-Details_MachineReadable.xlsx')\n",
    "SECTORS_DF = pd.read_excel('./data/FCBS_Sectors-Subsectors_MachineReadable.xlsx')\n",
    "ICE_DB_DF = pd.read_csv('./data/ICE DB_Cleaned.csv')\n",
    "CLF_EMBODIED_CARBON_DF = pd.read_csv('./data/CLF Embodied Carbon_Cleaned.csv')\n",
    "RIBA_TARGETS_DF = pd.read_excel('./data/RIBA 2030-Targets_MachineReadable.xlsx')\n",
    "\n",
    "# Fill missing values\n",
    "def fill_missing_values(df):\n",
    "    return df.fillna(0)\n",
    "\n",
    "ASPECTS_ELEMENTS_MATERIALS_DF = fill_missing_values(ASPECTS_ELEMENTS_MATERIALS_DF)\n",
    "BUILDUPS_DETAILS_DF = fill_missing_values(BUILDUPS_DETAILS_DF)\n",
    "SECTORS_DF = fill_missing_values(SECTORS_DF)\n",
    "ICE_DB_DF = fill_missing_values(ICE_DB_DF)\n",
    "CLF_EMBODIED_CARBON_DF = fill_missing_values(CLF_EMBODIED_CARBON_DF)\n",
    "RIBA_TARGETS_DF = fill_missing_values(RIBA_TARGETS_DF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Text Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': 2000.0, 'materials': ['timber', 'steel'], 'building_types': [], 'element_buildups': [], 'location': 'new york'}\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Extract unique materials and sub-materials\n",
    "unique_materials = ICE_DB_DF['Material'].unique()\n",
    "unique_sub_materials = ICE_DB_DF['Sub-material'].unique()\n",
    "all_materials = list(set(list(unique_materials) + list(unique_sub_materials)))\n",
    "all_materials = [str(material).strip().lower() for material in all_materials if pd.notna(material)]\n",
    "\n",
    "# Extract unique building types and uses from CLF Embodied Carbon dataset\n",
    "unique_building_types_clf = CLF_EMBODIED_CARBON_DF['Building Type'].unique()\n",
    "unique_building_uses_clf = CLF_EMBODIED_CARBON_DF['Building Use'].unique()\n",
    "# Extract unique sectors, building typologies, and sub-sectors from Sectors dataset\n",
    "unique_sectors = SECTORS_DF['Sector'].unique()\n",
    "unique_building_typologies = SECTORS_DF['Building Typology'].unique()\n",
    "unique_sub_sectors = SECTORS_DF['Sub-sector'].unique()\n",
    "# Combine all unique building types\n",
    "all_building_types = list(set(list(unique_building_types_clf) + list(unique_building_uses_clf) +\n",
    "                              list(unique_sectors) + list(unique_building_typologies) + list(unique_sub_sectors)))\n",
    "all_building_types = [str(building_type).strip().lower() for building_type in all_building_types if pd.notna(building_type)]\n",
    "\n",
    "# Extract unique element buildups from the Aspects Elements Materials dataset\n",
    "unique_element_buildups = ASPECTS_ELEMENTS_MATERIALS_DF[['Building Aspect', 'Element', 'Material']].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)), axis=1).unique()\n",
    "unique_element_buildups = [str(build_up).strip().lower() for build_up in unique_element_buildups if pd.notna(build_up)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a matcher for custom entities\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Function to create patterns from a list of terms\n",
    "def create_patterns(terms):\n",
    "    return [[{\"LOWER\": term}] for term in terms]\n",
    "\n",
    "# Create patterns for all materials, building types, and element buildups\n",
    "material_patterns = create_patterns(all_materials)\n",
    "building_type_patterns = create_patterns(all_building_types)\n",
    "element_buildup_patterns = create_patterns(unique_element_buildups)\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add(\"MATERIAL\", material_patterns)\n",
    "matcher.add(\"BUILDING_TYPE\", building_type_patterns)\n",
    "matcher.add(\"ELEMENT_BUILDUP\", element_buildup_patterns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_description(description):\n",
    "    doc = nlp(description)\n",
    "    size = 0\n",
    "    size_unit = 'square meters'\n",
    "    materials = []\n",
    "    building_types = []\n",
    "    location = 'unknown'\n",
    "    \n",
    "    # Use the matcher to find custom entities\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        match_label = nlp.vocab.strings[match_id]  # Get the string representation of the match ID\n",
    "        if match_label == 'MATERIAL':\n",
    "            materials.append(doc[start:end].text.lower())\n",
    "        elif match_label == 'BUILDING_TYPE':\n",
    "            building_types.append(doc[start:end].text.lower())\n",
    "    \n",
    "    # Use spaCy's NER to identify locations, quantities, and any building types/materials not captured by matcher\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'QUANTITY':\n",
    "            size = float(ent.text.replace(',', '').split()[0])\n",
    "            size_unit = ' '.join(ent.text.split()[1:])\n",
    "        elif ent.label_ == 'GPE':  # Geopolitical entity (locations)\n",
    "            location = ent.text.lower()\n",
    "        elif ent.label_ == 'ORG' or ent.label_ == 'FAC':  # Organizations and facilities\n",
    "            if not building_types:\n",
    "                building_types.append(ent.text.lower())\n",
    "        elif ent.label_ == 'PRODUCT':  # Products (could include materials)\n",
    "            if not materials:\n",
    "                materials.append(ent.text.lower())\n",
    "    \n",
    "    # Convert size to square meters if needed\n",
    "    if 'square feet' in size_unit or 'sq ft' in size_unit:\n",
    "        size *= 0.092903  # Convert square feet to square meters\n",
    "    \n",
    "    return {\n",
    "        'size': size,\n",
    "        'materials': materials,\n",
    "        'building_types': building_types,\n",
    "        'location': location\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "description = \"I am constructing a school building in New York that is 2000 square metres, primarily made of timber and steel.\"\n",
    "parsed_info = parse_description(description)\n",
    "print(parsed_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
